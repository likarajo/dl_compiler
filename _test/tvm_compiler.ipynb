{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Compiler: TVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TVM\n",
    "https://tvm.apache.org/docs/install/from_source.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/likarajo/tvm/python')\n",
    "sys.path.append('/Users/likarajo/tvm/topi/python')\n",
    "sys.path.append('/Users/likarajo/tvm/nnvm/python')\n",
    "sys.path.append('/Users/likarajo/tvm/vta/python')\n",
    "\n",
    "import tvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow\n",
    "https://www.tensorflow.org/install/\n",
    "\n",
    "## Dowload and extract existing model\n",
    "http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: mobilenet_v1_1.0_224\r\n",
      "Input: input\r\n",
      "Output: MobilenetV1/Predictions/Reshape_1\r\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cat 'models/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_info.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the existing TensorFlow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with tf.compat.v1.gfile.FastGFile(os.path.join('models/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen.pb'), 'rb') as f:\n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    graph = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the graph definition and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pytest\n",
    "except ImportError:\n",
    "    !pip3 install pytest\n",
    "    \n",
    "import tvm.relay.testing.tf as tf_testing\n",
    "graph_def = tf_testing.ProcessGraphDefParam(graph_def)\n",
    "\n",
    "shape_dict = {'input': (1, 244, 244, 3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import graph through frontend\n",
    "**Relay** comes as a submodule of TVM. \n",
    "* It is a high level intermediate representation for the TVM framework. \n",
    "* It replaces old computation graph based IRs such as NNVM with a more expressive IR that can be effectively optimized for many targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute data_format is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute is_training is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.batch_norm\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute ksize is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.avg_pool2d\n",
      "WARNING:root:Attribute explicit_paddings is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute use_cudnn_on_gpu is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.conv2d\n",
      "WARNING:root:Attribute T is ignored in relay.sym.squeeze\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.squeeze\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.squeeze\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.squeeze\n",
      "WARNING:root:Attribute T is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute Tshape is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute T is ignored in relay.sym.softmax\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.softmax\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.softmax\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.softmax\n",
      "WARNING:root:Attribute T is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute Tshape is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _output_shapes is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _node_name is ignored in relay.sym.reshape\n",
      "WARNING:root:Attribute _target_layout is ignored in relay.sym.reshape\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sym : tvm symbol graph constructed from imported model\n",
    "params : graph parameters imported from model\n",
    "\"\"\"\n",
    "sym, params = tvm.relay.frontend.from_tensorflow(graph_def, shape=shape_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model for LLVM target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Traceback (most recent call last):\n  [bt] (8) 9   libtvm.dylib                        0x0000000109c58007 tvm::relay::ExprMutator::VisitExpr_(tvm::relay::FunctionNode const*) + 903\n  [bt] (7) 8   libtvm.dylib                        0x0000000109c56af9 tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&) + 761\n  [bt] (6) 7   libtvm.dylib                        0x0000000109c563fb tvm::relay::MixedModeMutator::VisitLeaf(tvm::RelayExpr const&) + 331\n  [bt] (5) 6   libtvm.dylib                        0x0000000109c5dbb7 tvm::relay::PostOrderRewriter::DispatchVisitExpr(tvm::RelayExpr const&) + 55\n  [bt] (4) 5   libtvm.dylib                        0x0000000109a0045d tvm::relay::ExprRewriter::Rewrite(tvm::RelayExpr const&, tvm::RelayExpr const&) + 189\n  [bt] (3) 4   libtvm.dylib                        0x0000000109a00d22 tvm::NodeFunctor<tvm::RelayExpr (tvm::runtime::ObjectRef const&, tvm::relay::ExprRewriter*, tvm::RelayExpr const&)>::operator()(tvm::runtime::ObjectRef const&, tvm::relay::ExprRewriter*, tvm::RelayExpr const&) const + 306\n  [bt] (2) 3   libtvm.dylib                        0x0000000109a02539 tvm::relay::ExprRewriter::InitVTable()::'lambda4'(tvm::runtime::ObjectRef const&, tvm::relay::ExprRewriter*, tvm::RelayExpr const&)::__invoke(tvm::runtime::ObjectRef const&, tvm::relay::ExprRewriter*, tvm::RelayExpr const&) + 25\n  [bt] (1) 2   libtvm.dylib                        0x0000000109b19847 tvm::relay::legalize::Legalizer::Rewrite_(tvm::relay::CallNode const*, tvm::RelayExpr const&) + 1255\n  [bt] (0) 1   libtvm.dylib                        0x0000000109cf21c5 std::__1::__function::__func<TVMFuncCreateFromCFunc::$_2, std::__1::allocator<TVMFuncCreateFromCFunc::$_2>, void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>::operator()(tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&) + 213\n  File \"/Users/likarajo/tvm/python/tvm/target/codegen.py\", line 72, in llvm_version_major\n    return _ffi_api.llvm_version_major()\n  File \"/Users/likarajo/tvm/python/tvm/_ffi/_ctypes/packed_func.py\", line 81, in cfun\n    rv = local_pyfunc(*pyargs)\n  File \"/Users/likarajo/tvm/python/tvm/relay/op/nn/_nn.py\", line 140, in legalize_conv2d\n    return topi.nn.conv2d_legalize(attrs, inputs, types)\n  File \"</Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/decorator.py:decorator-gen-178>\", line 2, in conv2d_legalize\n  File \"/Users/likarajo/tvm/python/tvm/target/generic_func.py\", line 275, in dispatch_func\n    return dispatch_dict[k](*args, **kwargs)\n  File \"/Users/likarajo/tvm/python/tvm/topi/x86/conv2d_alter_op.py\", line 307, in _conv2d_legalize\n    if is_int8_hw_support(data_dtype, kernel_dtype):\n  File \"/Users/likarajo/tvm/python/tvm/topi/x86/conv2d_int8.py\", line 71, in is_int8_hw_support\n    llvm_version = tvm.target.codegen.llvm_version_major()\n  File \"/Users/likarajo/tvm/python/tvm/target/codegen.py\", line 76, in llvm_version_major\n    raise RuntimeError(\"LLVM version is not available, please check if you build with LLVM\")\nAttributeError: module 'tvm.target._ffi_api' has no attribute 'llvm_version_major'\nDuring handling of the above exception, another exception occurred:\n\nRuntimeError: LLVM version is not available, please check if you build with LLVM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d16bf483ca61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcompiler\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbuild\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'llvm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tvm/python/tvm/relay/build_module.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(mod, target, target_host, params, mod_name)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtophub_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mbld_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBuildModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mgraph_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbld_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_runtime_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphRuntimeFactoryModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvm/python/tvm/relay/build_module.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, mod, target, target_host, params)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mautotvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_auto_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mautotvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_autotvm_silent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvm/python/tvm/_ffi/_ctypes/packed_func.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         ):\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Traceback (most recent call last):\n  [bt] (8) 9   libtvm.dylib                        0x0000000109c58007 tvm::relay::ExprMutator::VisitExpr_(tvm::relay::FunctionNode const*) + 903\n  [bt] (7) 8   libtvm.dylib                        0x0000000109c56af9 tvm::relay::MixedModeMutator::VisitExpr(tvm::RelayExpr const&) + 761\n  [bt] (6) 7   libtvm.dylib                        0x0000000109c563fb tvm::relay::MixedModeMutator::VisitLeaf(tvm::RelayExpr const&) + 331\n  [bt] (5) 6   libtvm.dylib                        0x0000000109c5dbb7 tvm::relay::PostOrderRewriter::DispatchVisitExpr(tvm::RelayExpr const&) + 55\n  [bt] (4) 5   libtvm.dylib                        0x0000000109a0045d tvm::relay::ExprRewriter::Rewrite(tvm::RelayExpr const&, tvm::RelayExpr const&) + 189\n  [bt] (3) 4   libtvm.dylib                        0x0000000109a00d22 tvm::NodeFunctor<tvm::RelayExpr (tvm::runtime::ObjectRef const&, tvm::relay::ExprRewriter*, tvm::RelayExpr const&)>::operator()(tvm::runtime::ObjectRef const&, tvm::relay::ExprRewriter*, tvm::RelayExpr const&) const + 306\n  [bt] (2) 3   libtvm.dylib                        0x0000000109a02539 tvm::relay::ExprRewriter::InitVTable()::'lambda4'(tvm::runtime::ObjectRef const&, tvm::relay::ExprRewriter*, tvm::RelayExpr const&)::__invoke(tvm::runtime::ObjectRef const&, tvm::relay::ExprRewriter*, tvm::RelayExpr const&) + 25\n  [bt] (1) 2   libtvm.dylib                        0x0000000109b19847 tvm::relay::legalize::Legalizer::Rewrite_(tvm::relay::CallNode const*, tvm::RelayExpr const&) + 1255\n  [bt] (0) 1   libtvm.dylib                        0x0000000109cf21c5 std::__1::__function::__func<TVMFuncCreateFromCFunc::$_2, std::__1::allocator<TVMFuncCreateFromCFunc::$_2>, void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>::operator()(tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&) + 213\n  File \"/Users/likarajo/tvm/python/tvm/target/codegen.py\", line 72, in llvm_version_major\n    return _ffi_api.llvm_version_major()\n  File \"/Users/likarajo/tvm/python/tvm/_ffi/_ctypes/packed_func.py\", line 81, in cfun\n    rv = local_pyfunc(*pyargs)\n  File \"/Users/likarajo/tvm/python/tvm/relay/op/nn/_nn.py\", line 140, in legalize_conv2d\n    return topi.nn.conv2d_legalize(attrs, inputs, types)\n  File \"</Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/decorator.py:decorator-gen-178>\", line 2, in conv2d_legalize\n  File \"/Users/likarajo/tvm/python/tvm/target/generic_func.py\", line 275, in dispatch_func\n    return dispatch_dict[k](*args, **kwargs)\n  File \"/Users/likarajo/tvm/python/tvm/topi/x86/conv2d_alter_op.py\", line 307, in _conv2d_legalize\n    if is_int8_hw_support(data_dtype, kernel_dtype):\n  File \"/Users/likarajo/tvm/python/tvm/topi/x86/conv2d_int8.py\", line 71, in is_int8_hw_support\n    llvm_version = tvm.target.codegen.llvm_version_major()\n  File \"/Users/likarajo/tvm/python/tvm/target/codegen.py\", line 76, in llvm_version_major\n    raise RuntimeError(\"LLVM version is not available, please check if you build with LLVM\")\nAttributeError: module 'tvm.target._ffi_api' has no attribute 'llvm_version_major'\nDuring handling of the above exception, another exception occurred:\n\nRuntimeError: LLVM version is not available, please check if you build with LLVM"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "target: the compiler to build the output for\n",
    "\"\"\"\n",
    "graph, lib, params = tvm.relay.build(sym, target='llvm', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bitc9214b64ac504716b79c14caa4401eb5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
